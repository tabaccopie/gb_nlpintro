{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gb_nlpintro_hw09.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
      ],
      "metadata": {
        "id": "KpiqZ2nirGyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "UtQCTDLXrNg8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#загружаем файл\n",
        "text = open('dostoevsky.txt', 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Определяем длину текста (количество букв в нем)\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpBU25ELu7xB",
        "outputId": "e97511c5-1a9a-4813-ccd7-29367822c246"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1280652 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDGSKBHrvB5e",
        "outputId": "7172be9c-ff3c-4e9f-a2f2-4068ef51c552"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тут на горе паслось большое стадо свиней, и они просили Его, чтобы позволил им войти в них. Он позволил им. Бесы, вышедши из человека, вошли в свиней; и бросилось стадо с крутизны в озеро и потонуло. Пастухи, увидя случившееся, побежали и рассказали в городе и по деревням. И вышли жители смотреть случившееся и, пришедши к Иисусу, нашли человека, из которого вышли бесы, сидящего у ног Иисусовых, одетого и в здравом уме, и ужаснулись. Видевшие же рассказали им, как исцелился бесновавшийся.\n",
            "\n",
            "Еванге\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llnWK2HCvExl",
        "outputId": "f30859ff-32b9-47d8-f451-b44898d6a809"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "dlltg_7XvWOC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:200]), print(text_as_int[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMBFBJPOvZYL",
        "outputId": "066d99b0-24a2-448a-ba69-0a4853254a5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тут на горе паслось большое стадо свиней, и они просили Его, чтобы позволил им войти в них. Он позволил им. Бесы, вышедши из человека, вошли в свиней; и бросилось стадо с крутизны в озеро и потонуло. \n",
            "[ 99 129 128   1 123 110   1 113 124 126 115   1 125 110 127 121 124 127\n",
            " 138   1 111 124 121 138 134 124 115   1 127 128 110 114 124   1 127 112\n",
            " 118 123 115 119   6   1 118   1 124 123 118   1 125 126 124 127 118 121\n",
            " 118   1  87 113 124   6   1 133 128 124 111 137   1 125 124 117 112 124\n",
            " 121 118 121   1 118 122   1 112 124 119 128 118   1 112   1 123 118 131\n",
            "   8   1  95 123   1 125 124 117 112 124 121 118 121   1 118 122   8   1\n",
            "  83 115 127 137   6   1 112 137 134 115 114 134 118   1 118 117   1 133\n",
            " 115 121 124 112 115 120 110   6   1 112 124 134 121 118   1 112   1 127\n",
            " 112 118 123 115 119  20   1 118   1 111 126 124 127 118 121 124 127 138\n",
            "   1 127 128 110 114 124   1 127   1 120 126 129 128 118 117 123 137   1\n",
            " 112   1 124 117 115 126 124   1 118   1 125 124 128 124 123 129 121 124\n",
            "   8   1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(10):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RaBMrO-vcIl",
        "outputId": "c4915a5a-7f18-48da-9472-e0d236b5495c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Т\n",
            "у\n",
            "т\n",
            " \n",
            "н\n",
            "а\n",
            " \n",
            "г\n",
            "о\n",
            "р\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki_XJmT9vpa5",
        "outputId": "71ac5087-b022-4eb2-dbea-1d64c63a9c9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Тут на горе паслось большое стадо свиней, и они просили Его, чтобы позволил им войти в них. Он позвол'\n",
            "'ил им. Бесы, вышедши из человека, вошли в свиней; и бросилось стадо с крутизны в озеро и потонуло. Па'\n",
            "'стухи, увидя случившееся, побежали и рассказали в городе и по деревням. И вышли жители смотреть случи'\n",
            "'вшееся и, пришедши к Иисусу, нашли человека, из которого вышли бесы, сидящего у ног Иисусовых, одетог'\n",
            "'о и в здравом уме, и ужаснулись. Видевшие же рассказали им, как исцелился бесновавшийся.\\n\\nЕвангелие о'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем каждый батч на признаки и целевую переменную (последнюю букву)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#применяем функцию split_input_target ко всем батчам\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "4nRx_6Fcv_8q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset:\n",
        "    print(f'Количество батчей: {len(dataset)}')\n",
        "    print(f'Данные: {input_example}')\n",
        "    print(f'Целевая переменная: {target_example}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTuvnDgEwGq3",
        "outputId": "921d99de-0576-4bda-e8be-b243c9757df9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество батчей: 12679\n",
            "Данные: [ 99 129 128   1 123 110   1 113 124 126 115   1 125 110 127 121 124 127\n",
            " 138   1 111 124 121 138 134 124 115   1 127 128 110 114 124   1 127 112\n",
            " 118 123 115 119   6   1 118   1 124 123 118   1 125 126 124 127 118 121\n",
            " 118   1  87 113 124   6   1 133 128 124 111 137   1 125 124 117 112 124\n",
            " 121 118 121   1 118 122   1 112 124 119 128 118   1 112   1 123 118 131\n",
            "   8   1  95 123   1 125 124 117 112 124]\n",
            "Целевая переменная: [129 128   1 123 110   1 113 124 126 115   1 125 110 127 121 124 127 138\n",
            "   1 111 124 121 138 134 124 115   1 127 128 110 114 124   1 127 112 118\n",
            " 123 115 119   6   1 118   1 124 123 118   1 125 126 124 127 118 121 118\n",
            "   1  87 113 124   6   1 133 128 124 111 137   1 125 124 117 112 124 121\n",
            " 118 121   1 118 122   1 112 124 119 128 118   1 112   1 123 118 131   8\n",
            "   1  95 123   1 125 124 117 112 124 121]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yix9xVGuwKKV",
        "outputId": "91222ad5-d252-4b1c-9d3b-d76f941ef4fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'Тут на горе паслось большое стадо свиней, и они просили Его, чтобы позволил им войти в них. Он позво'\n",
            "Target data: 'ут на горе паслось большое стадо свиней, и они просили Его, чтобы позволил им войти в них. Он позвол'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyjdBSY3wR7d",
        "outputId": "82d6f2a5-8526-40c2-ca83-77105f281058"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "_t4CBp_jwTpw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JfTQC4nLwfAX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "DuUETSmcwq49"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7IUwuT0wsT_",
        "outputId": "86500561-6141-4024-989b-37e73c6966bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 150) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkyKyhGRw6Rq",
        "outputId": "c8fe1c83-83d6-4123-8b7d-75322206795a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           38400     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 150)           153750    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,617,238\n",
            "Trainable params: 30,617,238\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
        "\n",
        "#убираем лишнюю размерность (список индексов)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thLwk-6FxFYe",
        "outputId": "c7f40687-e774-4804-a709-284a8e114c5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([126, 129, 132,  77,  41, 143,  31,  48,  36,  89,  95,  85,  17,\n",
              "        67,  78,  49,  11, 119,  46, 138, 145, 122,  19,  39,   3,  82,\n",
              "        71,  79,  85, 106, 100, 127, 119,  99,  28, 132,  28,  49,  45,\n",
              "        12, 108,  69, 146,  14, 149,  84,  57,  75, 141,   0, 111,  40,\n",
              "        73, 141,  11,  38,  82, 132,  44,  13,  77,  27,  32,  86,  73,\n",
              "        12,  95,   6, 135,  37,  26,   6,  35, 127, 131,  38, 149,  31,\n",
              "        24, 111,  27,  48,  48,  42,  24,  60,   5,   4, 137,  10,  27,\n",
              "       128,  98,  74, 129,  98,  67, 116,  64, 122])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#входной пример\n",
        "#возвращаем строку\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "\n",
        "#предсказанная буква\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4j9nml7xPLk",
        "outputId": "52e08574-d794-4962-db17-60115fd7f06c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'л рядом с помещиком.\\n\\n– Еще ему сахару! – приказал Семен Яковлевич, когда уже налили стакан; положил'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'руцçT–JbOЗОГ8uèc2й]ь’м:R(АzéГЬУсйТGцGc[3Юx“5…Вkáя\\nбS»я2QАцZ4çFKД»3О,щPE,NсхQ…JCбFbbVCn*)ы1FтСàуСuжrм'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#функция для просчета loss\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TN-z4yTxWWN",
        "outputId": "e118959a-f6dd-44e9-cd61-fe6e27dbed44"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 150)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       5.0103226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "QXNa_0wIxfsD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраняем чекпоинты\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=100*5,\n",
        "    save_weights_only=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "xbW0NxnVxm9Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#обучаем модель\n",
        "\n",
        "num_epoch = 20\n",
        "history = model.fit(dataset, epochs=num_epoch, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLMCPzmkypUI",
        "outputId": "a9ea1e3b-c16e-4b1a-b448-29fbec4b95cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "198/198 [==============================] - 71s 351ms/step - loss: 1.2283\n",
            "Epoch 2/20\n",
            "198/198 [==============================] - 72s 359ms/step - loss: 1.1716\n",
            "Epoch 3/20\n",
            "198/198 [==============================] - 71s 353ms/step - loss: 1.1133\n",
            "Epoch 4/20\n",
            "198/198 [==============================] - 71s 353ms/step - loss: 1.0546\n",
            "Epoch 5/20\n",
            "198/198 [==============================] - 72s 359ms/step - loss: 0.9961\n",
            "Epoch 6/20\n",
            "198/198 [==============================] - 71s 354ms/step - loss: 0.9331\n",
            "Epoch 7/20\n",
            "198/198 [==============================] - 71s 355ms/step - loss: 0.8697\n",
            "Epoch 8/20\n",
            "198/198 [==============================] - 71s 351ms/step - loss: 0.8040\n",
            "Epoch 9/20\n",
            "198/198 [==============================] - 71s 354ms/step - loss: 0.7424\n",
            "Epoch 10/20\n",
            "198/198 [==============================] - 72s 357ms/step - loss: 0.6830\n",
            "Epoch 11/20\n",
            "198/198 [==============================] - 70s 349ms/step - loss: 0.6271\n",
            "Epoch 12/20\n",
            "198/198 [==============================] - 72s 358ms/step - loss: 0.5747\n",
            "Epoch 13/20\n",
            "198/198 [==============================] - 71s 352ms/step - loss: 0.5270\n",
            "Epoch 14/20\n",
            "198/198 [==============================] - 71s 353ms/step - loss: 0.4871\n",
            "Epoch 15/20\n",
            "198/198 [==============================] - 72s 358ms/step - loss: 0.4536\n",
            "Epoch 16/20\n",
            "198/198 [==============================] - 71s 354ms/step - loss: 0.4253\n",
            "Epoch 17/20\n",
            "198/198 [==============================] - 72s 359ms/step - loss: 0.4043\n",
            "Epoch 18/20\n",
            "198/198 [==============================] - 71s 353ms/step - loss: 0.3906\n",
            "Epoch 19/20\n",
            "198/198 [==============================] - 70s 349ms/step - loss: 0.3723\n",
            "Epoch 20/20\n",
            "198/198 [==============================] - 72s 358ms/step - loss: 0.3617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NuMwqEN4Dbfe",
        "outputId": "3bd90cf3-dc83-41b4-8312-99964d728547"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_20'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#строим модель\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "kttS_YMmDcO-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiSezfOrDnlw",
        "outputId": "8c351b4f-f960-4490-ec93-40375eb36902"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            38400     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (1, None, 1024)           5246976   \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 150)            153750    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,617,238\n",
            "Trainable params: 30,617,238\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "  \n",
        "    num_generate = 3000\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 0.03\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        \n",
        "        predictions = model(input_eval)\n",
        "       \n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))\n"
      ],
      "metadata": {
        "id": "JuZJ_QgrDoFQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ = generate_text(model, start_string=u\"На следующий день они \")\n",
        "print(text_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69JvC5WpEThn",
        "outputId": "310b8d69-ae6e-4fcc-e986-685575a5a0f6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На следующий день они за своею полною подписью. Каков!\n",
            "\n",
            "– Хуже всего то, что вы вывертываетесь. Многие повскочили с мест, иные с ним познакомился.\n",
            "\n",
            "– Это всё равно, – пролепетал Петр Степанович, как бы совсем не заметив мгновение за собой». Прибавлю, однако ж, что, кроме моего разрешения общественной формулы, насилу на стол и стал пред ним и, прежде всякого слова, пристально вгляделся в его лицо.\n",
            "\n",
            "– Ого уж так и будет. А старикашка согласится мигом. Каждый должен был бы ее принять на себя всю жизнь никуда не сойду. Хотите, встаньте и воды, – проговорила madame Виргинская.\n",
            "\n",
            "– Совершенно ничего. Ваша просьба исполняется, и вы навсегда устранили и теперь в его время, как и я сам.\n",
            "\n",
            "– Ну так знайте, что Шатов считает этот донос своих грязные свои острова и позволяет себе фамьли Степану Трофимовичу ее напечатать, за совершенною ее, в наше время, невинностью, но все почему-то старые посещения от Ставрогина была и поговорила с ним какой-то необычный шум шагов и голосов, подобный давешний испуг мгновенно исказил лицо ее, и опять она отшатнулась, подымая природу. Губернаторша пошла к кресту первать ваше совестью и с высокомерною улыбкой, как припоминая пред собою своею обыкновенною, обвиняя в правый учитель.\n",
            "\n",
            "– И дальше куда не я вам день и не жалаю, – произнес он истерически, – пред нами вся наша будущность, и если я уже не видал его в карете к Ставрогину, как человек еще молодой, несколько негодовал на груди руки и, бледный как мертвец, зловещим взглядом посмотрел на смеющуюся. «Вот в том и пройдет на ваш пятьдесят шаль, но он еще не знает, не знаю, как он сумасшедший; то уж само собою, тут влияли и посторонние поводы. У Петра Степановича действительно были некоторые замыслы на родительницы. Степан Трофимович стал оправлять. Она сердито смотрела в стену.\n",
            "\n",
            "– Не так, ох, не так… Что за руки!\n",
            "\n",
            "Шатов поправился, вдруг быстрый и работа есть деятельности, как и первые, противоей, и собрались у всей вздор, как же вы меня пугаете. Ну, навряда, служил по железным дорогам. Проснувшись, спросил котлетку, бутылку шато-д’икимая.\n",
            "\n",
            "– Какая полнола она не так тут придет, то как вы изволили раз выразиться.\n",
            "\n",
            "– Ничего нет великая грубость, что вновича и именно странно друга, а стало быть, очень не в высшем тоне) Степан Трофимович, – я узнал от него, что в тот же день смеялся, – прибавил Липутин и, как бы внезапно пораженный новою тупою улицу, в другой раз прицеживал. Это письмо был до столбных критей, которые всегда и которые вы так прочли, что это ничего? Для какая-то новая мысль: так что та наконец и упала… Я видел потом, не вылагает и сумму ночью ни слова, ни того, ни другого, не обманывал.\n",
            "\n",
            "– Вы атеист, потому что вал что некоторое влияние на Марью Тимофеевну и что она людей с офицерами, то найден наверное и постороннее, а после того как Степан Трофимович стал еще высокомерия.\n",
            "\n",
            "– Вы, кажется, очень обиделись на них, Марья Тимофеевна не только перестала смеяться, но сделалась ужасно глупо, господа, что всякий исполнит свой двадцатилетний студент, и, однако же, запереть бы крыльцо, а все-таки\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "===============================================\n",
        "\n",
        "Так же была попытка сделать модель на GRU слоях, но модель постоянно переобучалась и не удалось подобрать параметры для генерации хоть сколько нибудь осмысленного текста."
      ],
      "metadata": {
        "id": "5eJt5K62XZ5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Uqm_H7-XXtnk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}